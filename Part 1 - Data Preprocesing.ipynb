{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML is the future\n",
    "\n",
    "- genom\n",
    "- satu huruf 1 byte, \n",
    "    - 2005 = 130 exabytes\n",
    "    - 2010 = 1200 exabytes\n",
    "    - 2015 = 7900 exabytes\n",
    "    - 2020 = 40900 exabytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:\n",
    "1. numpy : perpustakaan matematika\n",
    "2. plt : merencanakan grafik yang bagus\n",
    "3. pandas : pustaka terbaik untuk mengimpor dataset dan mengelola dataset\n",
    "\n",
    "\n",
    "Import dataset ada 2 cara:\n",
    "1. pd.read_csv('Data.csv')\n",
    "2. read.csv('Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv(\"Y:/UDEMY\\ML A-Z HandsOn Python & R in DS/Part 1 - Data Preprocessing/Section 2 -Part 1 - Data Preprocessing/Data.csv\")\n",
    "\n",
    "# Mengapa harus membuat X dan y?\n",
    "# Karena kita akan bekerja dengan Numpy arrays, bukan Pandas dataframe.\n",
    "# Hal ini karena Numpy arrays adalah format yang sangat cocok untuk bekerja pada data pre-processing dan membangun model ML.\n",
    "\n",
    "# iloc = it location, menunjukkan kolom dengan indeks nya\n",
    "# .values digunakan untuk mengambil hasil dari kolom indeks yang dipilih dengan data berupa Numpy array.\n",
    "# .values yang membuat data X dan y menjadi Numpy arrays.\n",
    "\n",
    "# Independent data (input features)\n",
    "X = dataset.iloc[:, :-1].values\n",
    "# Dependent data (Apa yang akan diprediksi?)\n",
    "y = dataset.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ika Putri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:58: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Taking care of missing data\n",
    "# imputer adalah cara mengatasi missing value dengan menghubungkan data lain (misal mengambil rata-rata data)\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# artinya jika terdapat missing_value yaitu berisi 'Nan', maka hubungkan secara 'mean' dengan data lain\n",
    "# mean adalah cara terbaik untuk mengatasi missing value. \n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)\n",
    "# method .fit() yaitu menggunakan beberapa info data dimana objeknya berlaku.\n",
    "# tahap ini Imputer akan mengetahui missing_value pada kolom 1 dan 2 kemudian mengambil rata-rata kolom\n",
    "imputer = imputer.fit(X[:, 1:3])\n",
    "# method .transform() digunakan untuk transformasi data yang berlaku.\n",
    "# tahap ini Imputer akan mengganti missing_value pada kolom 1 dan 2 dengan 'mean'.\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X sudah berbentuk array dan sudah tidak ada missing value\n",
    "# cara kerja mean nya adalah menjumlahkan seluruh nilai yang tidak NaN, kemudian membagi dengan jumlah data yang tidak Nan.\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y juga sudah berbentuk array\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ika Putri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\Ika Putri\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Encoding categorical data\n",
    "# Encoding the Independent Variable\n",
    "labelencoder_X = LabelEncoder()\n",
    "# artinya cocokkan dan transform data X kolom 0 dengan LabelEncoder().\n",
    "# tahap ini yang merubah kategori string ke integer (merubah nama negara menjadi 0, 1, 2)\n",
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "# artinya cocokkan dan transform data X dengan OneHotEncoder().\n",
    "# tahap ini merubah kolom 0 yang berupa kategorik menjadi data dummy. karena ada 3 kategori di kolom 0, maka kolom 0 di transform menjadi 3 kolom (dummy).\n",
    "# tahap ini juga merubah bentuk isi kolom 1 dan 2. Misalnya 72000.0 berubah menjadi 7.2 * (10^4)\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "# Encoding the Dependent Variable\n",
    "# tahap ini yang merubah kategori string ke integer (merubah 'yes or no' menjadi 0, 1)\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 44.0, 72000.0],\n",
       "       [2, 27.0, 48000.0],\n",
       "       [1, 30.0, 54000.0],\n",
       "       [2, 38.0, 61000.0],\n",
       "       [1, 40.0, 63777.77777777778],\n",
       "       [0, 35.0, 58000.0],\n",
       "       [2, 38.77777777777778, 52000.0],\n",
       "       [0, 48.0, 79000.0],\n",
       "       [1, 50.0, 83000.0],\n",
       "       [0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X setelah di transform labelEncoder\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.40000000e+01,\n",
       "        7.20000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.70000000e+01,\n",
       "        4.80000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 3.00000000e+01,\n",
       "        5.40000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.80000000e+01,\n",
       "        6.10000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e+01,\n",
       "        6.37777778e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.50000000e+01,\n",
       "        5.80000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.87777778e+01,\n",
       "        5.20000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.80000000e+01,\n",
       "        7.90000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 5.00000000e+01,\n",
       "        8.30000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.70000000e+01,\n",
       "        6.70000000e+04]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X setelah di transform OneHotEncoder\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y setelah di transform labelEncoder\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset menjadi Training Set dan Test Set\n",
    "\n",
    "- training set adalah subset dari data dimana model akan belajar bagaimana memprediksi variabel independent menggunakan variabel dependent.\n",
    "- test set adalah subset dari data dimana kita akan mengevaluasi model untuk melihat apakah model yang dibangun sudah cukup baik dan bisa memprediksi dengan tepat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# artinya pembagian X_train, X_test, y_train, y_test dari data X dan y, dengan rasio test set 0.2 (20%).\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        4.00000000e+01, 6.37777778e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.70000000e+01, 6.70000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        2.70000000e+01, 4.80000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        3.87777778e+01, 5.20000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.80000000e+01, 7.90000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        3.80000000e+01, 6.10000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        4.40000000e+01, 7.20000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        3.50000000e+01, 5.80000000e+04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0e+00, 0.0e+00, 1.0e+00, 0.0e+00, 3.0e+01, 5.4e+04],\n",
       "       [1.0e+00, 0.0e+00, 1.0e+00, 0.0e+00, 5.0e+01, 8.3e+04]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "\n",
    "Fesature Scaling adalah metode \n",
    "\n",
    "Ada beberapa cara Feature Scaling, yaitu:\n",
    "1. Standard Scaler\n",
    "    - standard scaler digunakan untuk mengansumsikan data menjadi distribusi normal pada masing-masing fitur sehingga skala distribusinya yaitu centered berada sekitar 0 dan standar deviasi bernilai 1.\n",
    "    - tujuan : menjadikan data berdistribusi normal.\n",
    "    - rumusnya:     \n",
    "        $\\frac{x_i - \\text{mean($\\boldsymbol{x}$)}}{\\text{stdev($\\boldsymbol{x}$)}}$\n",
    "<img src = 1.png>\n",
    "\n",
    "2. Min-Max Scaler\n",
    "    - Min max Scaler adalah algoritma yang sangat terkenal.\n",
    "    - Min Max Scaler bekerja dengan baik ketika distribusinya bukan distribusi Gaussian atau ketika standar deviasinya sangat kecil. \n",
    "    - Dimana ini akan sangat sensitif dengan outlier, sehingga mungkin dapat dipertimbangkan untuk menggunakan robust scaler.\n",
    "    - Dalam hal ini, kemiringan distribusi dipertahankan, dan ketiga distribusi dibawa ke skala yang sama sehingga tumpang tindih.\n",
    "    - rumusnya:     \n",
    "        $\\frac{x_i - \\text{min}(\\boldsymbol{x})}{\\text{max}(\\boldsymbol{x}) - \\text{min}(\\boldsymbol{x})}$\n",
    "<img src = 2.png>\n",
    "    \n",
    "3. Robust Scaler\n",
    "    - Robust sama halnya dengan Min-Max Scaler, bekerja dengan baik ketika distribusinya bukan distribusi Gaussian atau standar deviasinya sangat kecil.\n",
    "    - Namun Robust Scaler akan menghilangkan median (pada pembilang) dan menggunakan rentang interkuartil (pada penyebut) yang akan membuat outlier tetap atau kuat.\n",
    "    - Robust Scaler membawa distribusi ke skala yang sama dan tumpang tindih, sementara outlier tetap berada di luar sebagian distribusi baru. Sedangkan Max-Min Scaler, 2 distribusi normal disimpan terpisah oleh outlier yang berada di dalam kisaran 0 dan 1.\n",
    "    - rumusnya:     \n",
    "        $\\frac{x_i - median(\\boldsymbol{x})}{Q_3(\\boldsymbol{x}) - Q_1(\\boldsymbol{x})}$\n",
    "<img src = 3.png>\n",
    "\n",
    "\n",
    "Variabel dummy dapat menggunakan Feature Scaling ini jika ingin mengoptimasi akurasi dari prediksi model.\n",
    "Variabel dummy tidak perlu menggunakan Feature Scaling ini jika ingin tetap menginterpretasi model dengan tepat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "sc_y = StandardScaler()\n",
    "y_train = sc_y.fit_transform(y_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.        ,  2.64575131, -0.77459667,  0.26306757,\n",
       "         0.12381479],\n",
       "       [-1.        ,  1.        , -0.37796447, -0.77459667, -0.25350148,\n",
       "         0.46175632],\n",
       "       [ 1.        , -1.        , -0.37796447,  1.29099445, -1.97539832,\n",
       "        -1.53093341],\n",
       "       [ 1.        , -1.        , -0.37796447,  1.29099445,  0.05261351,\n",
       "        -1.11141978],\n",
       "       [-1.        ,  1.        , -0.37796447, -0.77459667,  1.64058505,\n",
       "         1.7202972 ],\n",
       "       [ 1.        , -1.        , -0.37796447,  1.29099445, -0.0813118 ,\n",
       "        -0.16751412],\n",
       "       [-1.        ,  1.        , -0.37796447, -0.77459667,  0.95182631,\n",
       "         0.98614835],\n",
       "       [-1.        ,  1.        , -0.37796447, -0.77459667, -0.59788085,\n",
       "        -0.48214934]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -1.        ,  2.64575131, -0.77459667, -1.45882927,\n",
       "        -0.90166297],\n",
       "       [ 1.        , -1.        ,  2.64575131, -0.77459667,  1.98496442,\n",
       "         2.13981082]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77459667],\n",
       "       [ 0.77459667],\n",
       "       [ 0.77459667],\n",
       "       [-1.29099445],\n",
       "       [ 0.77459667],\n",
       "       [-1.29099445],\n",
       "       [-1.29099445],\n",
       "       [ 0.77459667]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
